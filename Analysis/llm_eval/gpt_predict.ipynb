{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba70dcf-eeef-4dda-9562-a8817d1460c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (1.82.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (1.82.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df89589-5226-498d-a0e1-f931b61f4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8776b67-10eb-4859-8c3e-a5d9ad3228ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae1746bc-bf97-4d75-8f60-0fe05a907b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(row):\n",
    "    return (\n",
    "        f\"Supppose there's a Knapsack instance with number_of_elements={int(row['number_of_elements'])}, \"\n",
    "        f\"capacity={row['capacity']}, \"\n",
    "        f\"max_weight={row['max_weight']}, min_weight={row['min_weight']}, \"\n",
    "        f\"mean_weight={row['mean_weight']}, median_weight={row['median_weight']}, std_weight={row['std_weight']}, \"\n",
    "        f\"weight_range={row['weight_range']}, \"\n",
    "        F\"max_profit={row['max_profit']}, min_profit={row['min_profit']}, \"\n",
    "        f\"mean_profit={row['mean_profit']}, median_profit={row['median_profit']}, std_profit={row['std_profit']}, \"\n",
    "        f\"profit_range={row['profit_range']}, \"\n",
    "        f\"renting_ratio={row['renting_ratio']}, \"\n",
    "        f\"mean_weight_profit_ratio={row['mean_weight_profit_ratio']}, \"\n",
    "        f\"median_weight_profit_ratio={row['median_weight_profit_ratio']}, \"\n",
    "        f\"capacity_mean_weight_ratio={row['capacity_mean_weight_ratio']}, \"\n",
    "        f\"capacity_median_weight_ratio={row['capacity_median_weight_ratio']}, \"\n",
    "        f\"capacity_std_weight_ratio={row['capacity_std_weight_ratio']}, \"\n",
    "        f\"std_weight_profit_ratio={row['std_weight_profit_ratio']}, \"\n",
    "        f\"weight_profit_correlation={row['weight_profit_correlation']}, \"\n",
    "        f\"cpu_cores={int(row['cpu_cores'])}, ram={int(row['ram'])}GB. \"\n",
    "        \"Based on these features, predict the **solution_time** (in milliseconds), **optimality_gap** (fraction), \"\n",
    "        \"**peak_memory** (in KB) if solved using the **branch and bound** algorithm for profit-maximization in 0-1 knapsack. \"\n",
    "        \"Return **only** a JSON object like :\\n \"\n",
    "        '{\"solution_time\": <double>, \"optimality_gap\": <double>, \"memory_kb\": <int>}.'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4dd4a8a-a480-4dc6-8e98-e44b854da7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_code(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```\") and text.endswith(\"```\"):\n",
    "        body = \"\\n\".join(text.splitlines()[1:-1])\n",
    "        return body.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6079f-5d88-4a13-bcee-f66421a3d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "df = pd.read_csv(\"input.csv\")  #Path to the instance-feature file for a specific algorithm\n",
    "\n",
    "\n",
    "\n",
    "output_path = \"output.csv\"\n",
    "cols = df.columns.tolist() + [\"solution_time\", \"optimality_gap\", \"memory_kb\"]\n",
    "pd.DataFrame(columns=cols).to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    prompt = build_prompt(row)\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        raw = resp.choices[0].message.content or \"\"\n",
    "        clean = strip_code(raw)\n",
    "        out = json.loads(clean)\n",
    "\n",
    "        row[\"solution_time\"]  = out[\"solution_time\"]\n",
    "        row[\"optimality_gap\"] = out[\"optimality_gap\"]\n",
    "        row[\"memory_kb\"]      = out[\"memory_kb\"]\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"[Row {idx}] JSON parse error: {e}\")\n",
    "        print(f\"[Row {idx}] Response:\\n{raw!r}\\n\")\n",
    "        row[\"solution_time\"]  = None\n",
    "        row[\"optimality_gap\"] = None\n",
    "        row[\"memory_kb\"]      = None\n",
    "\n",
    "    pd.DataFrame([row])[cols].to_csv(output_path, mode=\"a\", header=False, index=False)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797e9e2-b73c-4b03-935f-ed92709bfd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
