{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba70dcf-eeef-4dda-9562-a8817d1460c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df89589-5226-498d-a0e1-f931b61f4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8776b67-10eb-4859-8c3e-a5d9ad3228ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1746bc-bf97-4d75-8f60-0fe05a907b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(row):\n",
    "    return (\n",
    "        f\"Supppose there's a Knapsack instance with number_of_elements={int(row['number_of_elements'])}, \"\n",
    "        f\"capacity={row['capacity']}, \"\n",
    "        f\"max_weight={row['max_weight']}, min_weight={row['min_weight']}, \"\n",
    "        f\"mean_weight={row['mean_weight']}, median_weight={row['median_weight']}, std_weight={row['std_weight']}, \"\n",
    "        f\"weight_range={row['weight_range']}, \"\n",
    "        F\"max_profit={row['max_profit']}, min_profit={row['min_profit']}, \"\n",
    "        f\"mean_profit={row['mean_profit']}, median_profit={row['median_profit']}, std_profit={row['std_profit']}, \"\n",
    "        f\"profit_range={row['profit_range']}, \"\n",
    "        f\"renting_ratio={row['renting_ratio']}, \"\n",
    "        f\"mean_weight_profit_ratio={row['mean_weight_profit_ratio']}, \"\n",
    "        f\"median_weight_profit_ratio={row['median_weight_profit_ratio']}, \"\n",
    "        f\"capacity_mean_weight_ratio={row['capacity_mean_weight_ratio']}, \"\n",
    "        f\"capacity_median_weight_ratio={row['capacity_median_weight_ratio']}, \"\n",
    "        f\"capacity_std_weight_ratio={row['capacity_std_weight_ratio']}, \"\n",
    "        f\"std_weight_profit_ratio={row['std_weight_profit_ratio']}, \"\n",
    "        f\"weight_profit_correlation={row['weight_profit_correlation']}, \"\n",
    "        f\"cpu_cores={int(row['cpu_cores'])}, ram={int(row['ram'])}GB. \"\n",
    "        \"Based on these features, predict the **solution_time** (in milliseconds), **optimality_gap** (fraction), \"\n",
    "        \"**peak_memory** (in KB) if solved using the **branch and bound** algorithm for profit-maximization in 0-1 knapsack. \"\n",
    "        \"Return **only** a JSON object like :\\n \"\n",
    "        '{\"solution_time\": <double>, \"optimality_gap\": <double>, \"memory_kb\": <int>}.'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd4a8a-a480-4dc6-8e98-e44b854da7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_code(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```\") and text.endswith(\"```\"):\n",
    "        body = \"\\n\".join(text.splitlines()[1:-1])\n",
    "        return body.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6079f-5d88-4a13-bcee-f66421a3d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "df = pd.read_csv(\"input.csv\")  #Path to the instance-feature file for a specific algorithm\n",
    "\n",
    "\n",
    "\n",
    "output_path = \"output.csv\"\n",
    "cols = df.columns.tolist() + [\"solution_time\", \"optimality_gap\", \"memory_kb\"]\n",
    "pd.DataFrame(columns=cols).to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    prompt = build_prompt(row)\n",
    "\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        raw = resp.choices[0].message.content or \"\"\n",
    "        clean = strip_code(raw)\n",
    "        out = json.loads(clean)\n",
    "\n",
    "        row[\"solution_time\"]  = out[\"solution_time\"]\n",
    "        row[\"optimality_gap\"] = out[\"optimality_gap\"]\n",
    "        row[\"memory_kb\"]      = out[\"memory_kb\"]\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"[Row {idx}] JSON parse error: {e}\")\n",
    "        print(f\"[Row {idx}] Response:\\n{raw!r}\\n\")\n",
    "        row[\"solution_time\"]  = None\n",
    "        row[\"optimality_gap\"] = None\n",
    "        row[\"memory_kb\"]      = None\n",
    "\n",
    "    pd.DataFrame([row])[cols].to_csv(output_path, mode=\"a\", header=False, index=False)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797e9e2-b73c-4b03-935f-ed92709bfd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
