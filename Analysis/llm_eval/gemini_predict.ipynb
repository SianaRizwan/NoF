{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fada0e-f98e-43ab-9574-8af37f25e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community\n",
    "%pip install langchain\n",
    "%pip install -qU langchain_ollama\n",
    "%pip install sympy\n",
    "%pip install google-genai\n",
    "import pandas as pd\n",
    "from sympy import sympify\n",
    "from sympy.parsing.latex import parse_latex\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b923e-7fde-4094-a2e6-7d3bce7a6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gemini_API_KEY = \" Your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e178a-4c70-45cb-a889-67274e4726b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input.csv\")    #Path to the instance-feature file for a specific algorithm\n",
    "df[\"pred_solution_time\"]  = None\n",
    "df[\"pred_optimality_gap\"] = None\n",
    "df[\"pred_memory_kb\"]      = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ad1536e2-c882-4ea6-abc8-1a88449d32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(row):\n",
    "    return (\n",
    "        f\"Supppose there's a Knapsack instance with number_of_elements={int(row['number_of_elements'])}, \"\n",
    "        f\"capacity={row['capacity']}, \"\n",
    "        f\"max_weight={row['max_weight']}, min_weight={row['min_weight']}, \"\n",
    "        f\"mean_weight={row['mean_weight']}, median_weight={row['median_weight']}, std_weight={row['std_weight']}, \"\n",
    "        f\"weight_range={row['weight_range']}, \"\n",
    "        F\"max_profit={row['max_profit']}, min_profit={row['min_profit']}, \"\n",
    "        f\"mean_profit={row['mean_profit']}, median_profit={row['median_profit']}, std_profit={row['std_profit']}, \"\n",
    "        f\"profit_range={row['profit_range']}, \"\n",
    "        f\"renting_ratio={row['renting_ratio']}, \"\n",
    "        f\"mean_weight_profit_ratio={row['mean_weight_profit_ratio']}, \"\n",
    "        f\"median_weight_profit_ratio={row['median_weight_profit_ratio']}, \"\n",
    "        f\"capacity_mean_weight_ratio={row['capacity_mean_weight_ratio']}, \"\n",
    "        f\"capacity_median_weight_ratio={row['capacity_median_weight_ratio']}, \"\n",
    "        f\"capacity_std_weight_ratio={row['capacity_std_weight_ratio']}, \"\n",
    "        f\"std_weight_profit_ratio={row['std_weight_profit_ratio']}, \"\n",
    "        f\"weight_profit_correlation={row['weight_profit_correlation']}, \"\n",
    "        f\"cpu_cores={int(row['cpu_cores'])}, ram={int(row['ram'])}GB. \"\n",
    "        \"Based on these features, predict the **solution_time** (in milliseconds), **optimality_gap** (fraction), \"\n",
    "        \"**peak_memory** (in KB) if solved using the **branch and bound** algorithm for profit-maximization in 0-1 knapsack. \"\n",
    "        \"Consider time-limit set for the algorithm to run is 300seconds. \"\n",
    "        \"Return **only** a JSON object like :\\n \"\n",
    "        '{\"solution_time\": <double>, \"optimality_gap\": <double>, \"memory_kb\": <int>}.'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9bb1f9e5-d8f0-4f64-a56f-a85b18ade1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_code(s: str) -> str:\n",
    "  \n",
    "    lines = s.strip().splitlines()\n",
    "\n",
    "    if lines and lines[0].lstrip().startswith(\"```\"):\n",
    "        lines = lines[1:]\n",
    "    if lines and lines[-1].lstrip().startswith(\"```\"):\n",
    "        lines = lines[:-1]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43403225-c06b-4fd8-b2f2-722a7388674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text):\n",
    "    m = re.search(r'```json\\s*({.*?})\\s*```', text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    start = text.find('{')\n",
    "    end   = text.rfind('}')\n",
    "    if start != -1 and end != -1:\n",
    "        return text[start:end+1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba18cd7-c9ba-48e4-9d93-5648eb846ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [02:33<12:16, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row 7] ServerError: 502 Bad Gateway. {'message': '<!DOCTYPE html>\\n<html lang=en>\\n  <meta charset=utf-8>\\n  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\\n  <title>Error 502 (Server Error)!!1</title>\\n  <style>\\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\\n  </style>\\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\\n  <p><b>502.</b> <ins>That’s an error.</ins>\\n  <p>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.  <ins>That’s all we know.</ins>\\n', 'status': 'Bad Gateway'}. Assigning None and skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [18:11<00:00, 21.82s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from google import genai\n",
    "import google.genai.errors as genai_errors\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "client = genai.Client(api_key=\"Your-api-key\")\n",
    "\n",
    "output_path = \"output.csv\"\n",
    "\n",
    "\n",
    "df_head = pd.DataFrame(columns=df.columns)\n",
    "df_head.to_csv(output_path, index=False)\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    prompt = build_prompt(row)\n",
    "    try:\n",
    "        resp  = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-05-20\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        raw   = resp.text\n",
    "        clean = strip_code(raw)\n",
    "\n",
    "    \n",
    "        try:\n",
    "            out = json.loads(clean)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback to extracting a JSON substring\n",
    "            jstr = extract_json(raw)\n",
    "            if jstr:\n",
    "                out = json.loads(jstr)\n",
    "            else:\n",
    "                out = {}\n",
    "\n",
    "        # Assign predictions (will be None if missing)\n",
    "        df.at[idx, \"pred_solution_time\"]  = out.get(\"solution_time\")\n",
    "        df.at[idx, \"pred_optimality_gap\"] = out.get(\"optimality_gap\")\n",
    "        df.at[idx, \"pred_memory_kb\"]      = out.get(\"memory_kb\")\n",
    "\n",
    "    except genai_errors.ServerError as e:\n",
    "        print(f\"[Row {idx}] ServerError: {e}. Assigning None and skipping.\")\n",
    "        df.at[idx, \"pred_solution_time\"]  = None\n",
    "        df.at[idx, \"pred_optimality_gap\"] = None\n",
    "        df.at[idx, \"pred_memory_kb\"]      = None\n",
    "\n",
    "    \n",
    "    df.iloc[[idx]].to_csv(output_path, mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
