{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487aaad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (1.15.2)\n",
      "Requirement already satisfied: plotly in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (6.0.1)\n",
      "Requirement already satisfied: six in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/jovyan/conda-envs/torch-gpu/lib/python3.12/site-packages (from plotly->catboost) (1.37.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:01:32.388588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747861292.411024  249835 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747861292.418200  249835 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747861292.436820  249835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747861292.436838  249835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747861292.436840  249835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747861292.436842  249835 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-21 21:01:32.443200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "from itertools import combinations\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a45195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(y_true, y_pred, solver_name, target, model_combo, weights):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n[ENSEMBLE] Solver: {solver_name}, Target: {target}, Models: {model_combo}, Weights: {weights}\")\n",
    "    print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "    return {\n",
    "        \"Solver\": solver_name,\n",
    "        \"Target\": target,\n",
    "        \"Models\": \"_\".join(model_combo),\n",
    "        \"Weights\": str(weights),\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7079d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_for_combination(model_name, solver_name, target, X_test, X_test_cnn):\n",
    "    try:\n",
    "        if model_name == \"rf\":\n",
    "            path = f\"./rf_reg/rf_models/rf_model_{solver_name}_{target}.joblib\"\n",
    "            if os.path.exists(path):\n",
    "                model = joblib.load(path)\n",
    "                return model_name, model.predict(X_test)\n",
    "        elif model_name == \"cb\":\n",
    "            path = f\"./cb_reg/cb_models/cb_model_{solver_name}_{target}.cbm\"\n",
    "            if os.path.exists(path):\n",
    "                model = CatBoostRegressor()\n",
    "                model.load_model(path)\n",
    "                return model_name, model.predict(X_test)\n",
    "        elif model_name == \"cnn\":\n",
    "            path = f\"./cnn_reg/cnn_models/cnn_model_{solver_name}_{target}.h5\"\n",
    "            if os.path.exists(path):\n",
    "                model = load_model(path, custom_objects={'mse': MeanSquaredError()})\n",
    "                return model_name, model.predict(X_test_cnn).flatten()\n",
    "        elif model_name == \"mlp\":\n",
    "            path = f\"./mlp_reg/mlp_models/mlp_model_{solver_name}_{target}.h5\"\n",
    "            if os.path.exists(path):\n",
    "                model = load_model(path, custom_objects={'mse': MeanSquaredError()})\n",
    "                return model_name, model.predict(X_test).flatten()\n",
    "        elif model_name == \"svm\":\n",
    "            path = f\"./svm_reg/svm_models/svm_model_{solver_name}_{target}.joblib\"\n",
    "            if os.path.exists(path):\n",
    "                model = joblib.load(path)\n",
    "                return model_name, model.predict(X_test)\n",
    "        elif model_name == \"lr\":\n",
    "            path = f\"./lr_reg/lr_models/lr_model_{solver_name}_{target}.joblib\"\n",
    "            if os.path.exists(path):\n",
    "                model = joblib.load(path)\n",
    "                return model_name, model.predict(X_test)\n",
    "        elif model_name == \"dt\":\n",
    "            path = f\"./dt_reg/dt_models/dt_model_{solver_name}_{target}.joblib\"\n",
    "            if os.path.exists(path):\n",
    "                model = joblib.load(path)\n",
    "                return model_name, model.predict(X_test)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {model_name} for {solver_name}, {target}: {e}\")\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def rank_models_by_performance(solver_name, test_file, target, X_test, X_test_cnn, y_test):\n",
    "    all_models = [\"rf\", \"cb\", \"cnn\", \"mlp\", \"svm\", \"lr\", \"dt\"]\n",
    "    model_performance = {}\n",
    "\n",
    "    for model_name in all_models:\n",
    "        name, pred = load_model_for_combination(model_name, solver_name, target, X_test, X_test_cnn)\n",
    "        if pred is not None:\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "            model_performance[model_name] = rmse\n",
    "            print(f\"{model_name} RMSE: {rmse:.4f}\")\n",
    "        else:\n",
    "            print(f\"{model_name} not evaluated.\")\n",
    "\n",
    "    # Sort models by RMSE\n",
    "    ranked_models = sorted(model_performance, key=model_performance.get)\n",
    "    print(f\"Models ranked by RMSE for {target}: {ranked_models}\")\n",
    "    return ranked_models, model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa839151-b8f6-435d-8f9d-591cf08a8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def run_top_k_ensemble_dynamic(solver_name, train_file, test_file):\n",
    "    \n",
    "    df_train = pd.read_csv(train_file)\n",
    "    df_test  = pd.read_csv(test_file)\n",
    "    df_test.dropna(inplace=True)\n",
    "\n",
    " \n",
    "    features = [\n",
    "        \"number_of_elements\",\"capacity\",\"max_weight\",\"min_weight\",\"mean_weight\",\n",
    "        \"median_weight\",\"std_weight\",\"weight_range\",\"max_profit\",\"min_profit\",\"mean_profit\",\n",
    "        \"median_profit\",\"std_profit\",\"profit_range\",\"renting_ratio\",\"mean_weight_profit_ratio\",\n",
    "        \"median_weight_profit_ratio\",\"capacity_mean_weight_ratio\",\"capacity_median_weight_ratio\",\n",
    "        \"capacity_std_weight_ratio\",\"std_weight_profit_ratio\",\"weight_profit_correlation\",\n",
    "        \"ram\",\"cpu_cores\"\n",
    "    ]\n",
    "    targets = [\"solution_time\",\"optimality_gap\",\"peak_memory\"]\n",
    "\n",
    "   \n",
    "    feat_scaler = StandardScaler().fit(df_train[features])\n",
    "    X_test      = feat_scaler.transform(df_test[features])\n",
    "    X_test_cnn  = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "  \n",
    "    y_scalers = {\n",
    "        t: StandardScaler().fit(df_train[[t]].values)\n",
    "        for t in targets\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target in targets:\n",
    "        y_test = df_test[target].values\n",
    "\n",
    "       \n",
    "        ranked_models, _ = rank_models_by_performance(\n",
    "            solver_name, test_file, target, X_test, X_test_cnn, y_test\n",
    "        )\n",
    "\n",
    "        for k in [3, 5, 7]:\n",
    "            ensemble_preds = []\n",
    "            names = []\n",
    "\n",
    "            for mname in ranked_models[:k]:\n",
    "                name, pred = load_model_for_combination(\n",
    "                    mname, solver_name, target, X_test, X_test_cnn\n",
    "                )\n",
    "                if pred is None:\n",
    "                    continue\n",
    "\n",
    "               \n",
    "                if name in {\"cnn\",\"mlp\",\"dt\",\"rf\",\"svm\"}:\n",
    "                    pred = y_scalers[target].inverse_transform(pred.reshape(-1,1)).flatten()\n",
    "\n",
    "                ensemble_preds.append(pred)\n",
    "                names.append(name)\n",
    "\n",
    "            if not ensemble_preds:\n",
    "                print(f\"No models for Top-{k} on {solver_name}/{target}\")\n",
    "                continue\n",
    "\n",
    "            #Equal‐weight average\n",
    "            P = np.vstack(ensemble_preds)\n",
    "            avg_pred = P.mean(axis=0)\n",
    "\n",
    "            row = evaluate_ensemble(\n",
    "                y_test, avg_pred, solver_name, target, tuple(names),\n",
    "                weights=[1/len(P)]*len(P)\n",
    "            )\n",
    "            row[\"Top_K\"] = k\n",
    "            results.append(row)\n",
    "\n",
    "    df_res = pd.DataFrame(results)\n",
    "    out_path = \"output.csv\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    df_res.to_csv(out_path, mode=\"a\", index=False,\n",
    "                  header=not os.path.exists(out_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58890091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensembles_for_all_solvers(base_folder):\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for folder in dirs:\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            csv_files = os.listdir(folder_path)\n",
    "\n",
    "            train_file = [f for f in csv_files if f.endswith(\"_train.csv\")]\n",
    "            test_file = [f for f in csv_files if f.endswith(\"_test.csv\")]\n",
    "\n",
    "            if test_file:\n",
    "                train_fp = os.path.join(folder_path, train_file[0])\n",
    "                test_fp = os.path.join(folder_path, test_file[0])\n",
    "                solver_name = folder\n",
    "\n",
    "                print(f\"\\nRunning for: {solver_name}\")\n",
    "                run_top_k_ensemble_dynamic(solver_name, train_fp, test_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ensembles for solver: or_min\n",
      "rf RMSE: 2.0257\n",
      "cb RMSE: 2.2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747861296.129000  249835 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22377 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "I0000 00:00:1747861296.131763  249835 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22377 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747861297.612938  250892 service.cc:152] XLA service 0x76d37c0067b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747861297.612981  250892 service.cc:160]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "I0000 00:00:1747861297.612987  250892 service.cc:160]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2025-05-21 21:01:37.633006: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747861297.695851  250892 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 859ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747861298.257769  250892 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step \n",
      "cnn RMSE: 2.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2025-05-21 21:01:39.929262: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-21 21:01:40.041137: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_16', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step\n",
      "mlp RMSE: 2.2730\n",
      "svm RMSE: 2.1123\n",
      "lr RMSE: 136139.6596\n",
      "dt RMSE: 2.1321\n",
      "Top models ranked by RMSE for solution_time: ['rf', 'svm', 'dt', 'cnn', 'cb', 'mlp', 'lr']\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: solution_time, Models: ('rf', 'svm', 'dt'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 4.7912, RMSE: 12.7617, R2: -41.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: solution_time, Models: ('rf', 'svm', 'dt', 'cnn', 'cb'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 4.4113, RMSE: 15.1558, R2: -58.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: solution_time, Models: ('rf', 'svm', 'dt', 'cnn', 'cb', 'mlp', 'lr'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 18347.3469, RMSE: 19446.6445, R2: -98625800.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 0.0941\n",
      "cb RMSE: 0.0226\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "cnn RMSE: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 0.0958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 0.1172\n",
      "lr RMSE: 938.3911\n",
      "dt RMSE: 0.0942\n",
      "Top models ranked by RMSE for optimality_gap: ['cb', 'rf', 'dt', 'mlp', 'cnn', 'svm', 'lr']\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: optimality_gap, Models: ('cb', 'rf', 'dt'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0037, RMSE: 0.0076, R2: -12.7034\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step \n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: optimality_gap, Models: ('cb', 'rf', 'dt', 'mlp', 'cnn'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0049, RMSE: 0.0146, R2: -49.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: optimality_gap, Models: ('cb', 'rf', 'dt', 'mlp', 'cnn', 'svm', 'lr'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 129.5220, RMSE: 134.0543, R2: -4246908781.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 410939.7735\n",
      "cb RMSE: 43962.9334\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn RMSE: 410939.8287\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "mlp RMSE: 410939.7888\n",
      "svm RMSE: 410939.7329\n",
      "lr RMSE: 122593932.1187\n",
      "dt RMSE: 410939.7797\n",
      "Top models ranked by RMSE for peak_memory: ['cb', 'svm', 'rf', 'dt', 'mlp', 'cnn', 'lr']\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: peak_memory, Models: ('cb', 'svm', 'rf'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 22490.1679, RMSE: 42527.6420, R2: 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: peak_memory, Models: ('cb', 'svm', 'rf', 'dt', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 21988.9126, RMSE: 41572.7207, R2: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: or_min, Target: peak_memory, Models: ('cb', 'svm', 'rf', 'dt', 'mlp', 'cnn', 'lr'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 16679919.1655, RMSE: 17514292.4650, R2: -157356.1741\n",
      "\n",
      "Running ensembles for solver: gurobi_min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 0.4586\n",
      "cb RMSE: 0.0253\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "cnn RMSE: 0.7120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "mlp RMSE: 0.5928\n",
      "svm RMSE: 0.6675\n",
      "lr RMSE: 0.0289\n",
      "dt RMSE: 0.5849\n",
      "Top models ranked by RMSE for solution_time: ['cb', 'lr', 'rf', 'dt', 'mlp', 'svm', 'cnn']\n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: solution_time, Models: ('cb', 'lr', 'rf'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0185, RMSE: 0.0246, R2: 0.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: solution_time, Models: ('cb', 'lr', 'rf', 'dt', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0185, RMSE: 0.0248, R2: 0.4943\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: solution_time, Models: ('cb', 'lr', 'rf', 'dt', 'mlp', 'svm', 'cnn'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.0186, RMSE: 0.0250, R2: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 0.0000\n",
      "cb not evaluated.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "cnn RMSE: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "mlp RMSE: 0.0000\n",
      "svm RMSE: 0.0000\n",
      "lr RMSE: 0.0000\n",
      "dt RMSE: 0.0000\n",
      "Top models ranked by RMSE for optimality_gap: ['rf', 'svm', 'lr', 'dt', 'cnn', 'mlp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: optimality_gap, Models: ('rf', 'svm', 'lr'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: optimality_gap, Models: ('rf', 'svm', 'lr', 'dt', 'cnn'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: optimality_gap, Models: ('rf', 'svm', 'lr', 'dt', 'cnn', 'mlp'), Weights: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 0.0000\n",
      "rf RMSE: 189134.3186\n",
      "cb RMSE: 21402.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "cnn RMSE: 189134.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 189134.2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 189134.4264\n",
      "lr RMSE: 20640.3526\n",
      "dt RMSE: 189134.2784\n",
      "Top models ranked by RMSE for peak_memory: ['lr', 'cb', 'cnn', 'dt', 'mlp', 'rf', 'svm']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: peak_memory, Models: ('lr', 'cb', 'cnn'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 17513.1792, RMSE: 21164.9264, R2: 0.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step \n",
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: peak_memory, Models: ('lr', 'cb', 'cnn', 'dt', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 16707.5360, RMSE: 20496.0714, R2: 0.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: gurobi_min, Target: peak_memory, Models: ('lr', 'cb', 'cnn', 'dt', 'mlp', 'rf', 'svm'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 17049.1435, RMSE: 21032.8177, R2: 0.0894\n",
      "\n",
      "Running ensembles for solver: greedy_min\n",
      "rf RMSE: 0.9203\n",
      "cb RMSE: 0.0059\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "cnn RMSE: 0.9037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "mlp RMSE: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 0.9209\n",
      "lr RMSE: 0.0039\n",
      "dt RMSE: 0.9232\n",
      "Top models ranked by RMSE for solution_time: ['lr', 'cb', 'mlp', 'cnn', 'rf', 'svm', 'dt']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: solution_time, Models: ('lr', 'cb', 'mlp'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0029, RMSE: 0.0040, R2: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: solution_time, Models: ('lr', 'cb', 'mlp', 'cnn', 'rf'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0027, RMSE: 0.0039, R2: 0.9962\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: solution_time, Models: ('lr', 'cb', 'mlp', 'cnn', 'rf', 'svm', 'dt'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.0025, RMSE: 0.0037, R2: 0.9966\n",
      "rf RMSE: 28.7751\n",
      "cb RMSE: 24.4769\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn RMSE: 28.8168\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "mlp RMSE: 28.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 28.8244\n",
      "lr RMSE: 25.7908\n",
      "dt RMSE: 28.8196\n",
      "Top models ranked by RMSE for optimality_gap: ['cb', 'lr', 'rf', 'cnn', 'dt', 'svm', 'mlp']\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: optimality_gap, Models: ('cb', 'lr', 'rf'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 15.4735, RMSE: 24.5256, R2: -0.2562\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: optimality_gap, Models: ('cb', 'lr', 'rf', 'cnn', 'dt'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 15.4355, RMSE: 24.6467, R2: -0.2686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: optimality_gap, Models: ('cb', 'lr', 'rf', 'cnn', 'dt', 'svm', 'mlp'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 15.4975, RMSE: 24.8922, R2: -0.2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 6144.0000\n",
      "cb not evaluated.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "cnn RMSE: 6144.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "mlp RMSE: 6144.0000\n",
      "svm RMSE: 6144.0000\n",
      "lr RMSE: 0.0000\n",
      "dt RMSE: 6144.0000\n",
      "Top models ranked by RMSE for peak_memory: ['lr', 'rf', 'cnn', 'mlp', 'svm', 'dt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn', 'mlp', 'svm'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: greedy_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn', 'mlp', 'svm', 'dt'), Weights: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n",
      "\n",
      "Running ensembles for solver: ga_min\n",
      "rf RMSE: 1.8697\n",
      "cb RMSE: 0.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
      "cnn RMSE: 1.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 1.8787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 1.8755\n",
      "lr RMSE: 0.0316\n",
      "dt RMSE: 1.8688\n",
      "Top models ranked by RMSE for solution_time: ['lr', 'cb', 'cnn', 'dt', 'rf', 'svm', 'mlp']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: solution_time, Models: ('lr', 'cb', 'cnn'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0291, RMSE: 0.0366, R2: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: solution_time, Models: ('lr', 'cb', 'cnn', 'dt', 'rf'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0264, RMSE: 0.0322, R2: 0.9985\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: solution_time, Models: ('lr', 'cb', 'cnn', 'dt', 'rf', 'svm', 'mlp'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.0216, RMSE: 0.0259, R2: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf RMSE: 5225874.8605\n",
      "cb RMSE: 8883247.1462\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "cnn RMSE: 5225874.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "mlp RMSE: 5225874.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 5225874.8794\n",
      "lr RMSE: 23117346.3466\n",
      "dt RMSE: 5225874.7082\n",
      "Top models ranked by RMSE for optimality_gap: ['cnn', 'dt', 'rf', 'svm', 'mlp', 'cb', 'lr']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: optimality_gap, Models: ('cnn', 'dt', 'rf'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 4945620.8517, RMSE: 20704533.7331, R2: -16.1434\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step \n",
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: optimality_gap, Models: ('cnn', 'dt', 'rf', 'svm', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 7281121.0977, RMSE: 18419405.1764, R2: -12.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: optimality_gap, Models: ('cnn', 'dt', 'rf', 'svm', 'mlp', 'cb', 'lr'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 6768266.0255, RMSE: 15270827.6881, R2: -8.3259\n",
      "rf RMSE: 6020.7737\n",
      "cb RMSE: 10.7115\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
      "cnn RMSE: 6020.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 6020.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 6020.6234\n",
      "lr RMSE: 492.7974\n",
      "dt RMSE: 6020.7737\n",
      "Top models ranked by RMSE for peak_memory: ['cb', 'lr', 'mlp', 'cnn', 'svm', 'rf', 'dt']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 144.1691, RMSE: 339.4771, R2: 0.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp', 'cnn', 'svm'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 147.0853, RMSE: 415.4692, R2: 0.3795\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: ga_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp', 'cnn', 'svm', 'rf', 'dt'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 105.0610, RMSE: 296.7637, R2: 0.6834\n",
      "\n",
      "Running ensembles for solver: dp_min\n",
      "rf RMSE: 6.1087\n",
      "cb RMSE: 0.8843\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "cnn RMSE: 6.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step \n",
      "mlp RMSE: 6.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 6.1551\n",
      "lr RMSE: 1.5579\n",
      "dt RMSE: 6.0932\n",
      "Top models ranked by RMSE for solution_time: ['cb', 'lr', 'dt', 'cnn', 'rf', 'mlp', 'svm']\n",
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: solution_time, Models: ('cb', 'lr', 'dt'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.5356, RMSE: 0.8265, R2: 0.9494\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: solution_time, Models: ('cb', 'lr', 'dt', 'cnn', 'rf'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.4259, RMSE: 0.7182, R2: 0.9618\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: solution_time, Models: ('cb', 'lr', 'dt', 'cnn', 'rf', 'mlp', 'svm'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.3846, RMSE: 0.5978, R2: 0.9735\n",
      "rf RMSE: 0.0922\n",
      "cb RMSE: 0.0103\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "cnn RMSE: 0.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 0.1134\n",
      "svm RMSE: 0.1228\n",
      "lr RMSE: 0.3234\n",
      "dt RMSE: 0.0922\n",
      "Top models ranked by RMSE for optimality_gap: ['cb', 'cnn', 'rf', 'dt', 'mlp', 'svm', 'lr']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: optimality_gap, Models: ('cb', 'cnn', 'rf'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0021, RMSE: 0.0051, R2: -313.6447\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: optimality_gap, Models: ('cb', 'cnn', 'rf', 'dt', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0050, RMSE: 0.0226, R2: -6154.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: optimality_gap, Models: ('cb', 'cnn', 'rf', 'dt', 'mlp', 'svm', 'lr'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.0403, RMSE: 0.0624, R2: -46897.7104\n",
      "rf RMSE: 12512.5918\n",
      "cb RMSE: 29.7820\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "cnn RMSE: 12512.5869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "mlp RMSE: 12512.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 12512.8451\n",
      "lr RMSE: 464.8259\n",
      "dt RMSE: 12512.5887\n",
      "Top models ranked by RMSE for peak_memory: ['cb', 'lr', 'mlp', 'cnn', 'dt', 'rf', 'svm']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 131.5840, RMSE: 184.4943, R2: 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp', 'cnn', 'dt'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 84.8632, RMSE: 114.3044, R2: 0.9432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: dp_min, Target: peak_memory, Models: ('cb', 'lr', 'mlp', 'cnn', 'dt', 'rf', 'svm'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 85.3571, RMSE: 135.3199, R2: 0.9205\n",
      "\n",
      "Running ensembles for solver: bb_min\n",
      "rf RMSE: 0.9425\n",
      "cb RMSE: 0.0000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "cnn RMSE: 0.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "mlp RMSE: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 0.9439\n",
      "lr RMSE: 0.0000\n",
      "dt RMSE: 0.9328\n",
      "Top models ranked by RMSE for solution_time: ['lr', 'cb', 'cnn', 'mlp', 'dt', 'rf', 'svm']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: solution_time, Models: ('lr', 'cb', 'cnn'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step \n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: solution_time, Models: ('lr', 'cb', 'cnn', 'mlp', 'dt'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: solution_time, Models: ('lr', 'cb', 'cnn', 'mlp', 'dt', 'rf', 'svm'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 0.9949\n",
      "rf RMSE: 29.3846\n",
      "cb RMSE: 8.2672\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "cnn RMSE: 29.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "mlp RMSE: 29.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm RMSE: 29.1829\n",
      "lr RMSE: 11.9099\n",
      "dt RMSE: 29.3912\n",
      "Top models ranked by RMSE for optimality_gap: ['cb', 'lr', 'svm', 'cnn', 'mlp', 'rf', 'dt']\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: optimality_gap, Models: ('cb', 'lr', 'svm'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 5.0069, RMSE: 8.6131, R2: 0.8953\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: optimality_gap, Models: ('cb', 'lr', 'svm', 'cnn', 'mlp'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "MAE: 4.1716, RMSE: 6.8621, R2: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: optimality_gap, Models: ('cb', 'lr', 'svm', 'cnn', 'mlp', 'rf', 'dt'), Weights: [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285]\n",
      "MAE: 3.4653, RMSE: 6.0555, R2: 0.9483\n",
      "rf RMSE: 4096.0000\n",
      "cb not evaluated.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "cnn RMSE: 4096.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp RMSE: 4096.0000\n",
      "svm RMSE: 4096.0000\n",
      "lr RMSE: 0.0000\n",
      "dt RMSE: 4096.0000\n",
      "Top models ranked by RMSE for peak_memory: ['lr', 'rf', 'cnn', 'mlp', 'svm', 'dt']\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn'), Weights: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn', 'mlp', 'svm'), Weights: [0.2, 0.2, 0.2, 0.2, 0.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\n",
      "[ENSEMBLE] Solver: bb_min, Target: peak_memory, Models: ('lr', 'rf', 'cnn', 'mlp', 'svm', 'dt'), Weights: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "MAE: 0.0000, RMSE: 0.0000, R2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "base_folder = \"./training_data\"  #Path to training data folder\n",
    "run_ensembles_for_all_solvers(base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c76c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
