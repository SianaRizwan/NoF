{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2c2f5-eb8b-45dd-a2d3-4f51438592b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import MeanSquaredError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af8fba-ae41-4389-884f-0e5280408531",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DPI   = \"./training_data/algorithms\"     #path to the folder that contains training dataset for algorithms\n",
    "BINS_BASE  = \"./trainingData/bins\"      #path to the folder that contains bins for algorithms\n",
    "CLASS_BASE = \"./outupt_folder\"                  \n",
    "K_LIST     = [3,5,7]                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefc6b1-4652-4f16-bab0-346d0220ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_proba(name, solver, target, X, X_cnn):\n",
    "\n",
    "    try:\n",
    "        if name == \"rf\":\n",
    "            p = f\"{CLASS_BASE}/rf_class/rf_classifier_models/rf_{solver}_{target}.joblib\"\n",
    "            if os.path.exists(p):\n",
    "                m = joblib.load(p); return name, m.predict_proba(X), p\n",
    "\n",
    "        if name == \"cb\":\n",
    "            p = f\"{CLASS_BASE}/cb_class/cb_classifier_models/cb_{solver}_{target}.cbm\"\n",
    "            if os.path.exists(p):\n",
    "                m = CatBoostClassifier(); m.load_model(p)\n",
    "                return name, m.predict_proba(X), p\n",
    "\n",
    "        if name == \"cnn\":\n",
    "           \n",
    "            pattern = f\"{CLASS_BASE}/cnn_class/cnn_classifier_models/cnn_classifier_{solver}_{target}_*e.h5\"\n",
    "            files   = glob.glob(pattern)\n",
    "            if not files:\n",
    "                return name, None, None\n",
    "            \n",
    "            fpath = sorted(files, key=lambda s: int(s.split(\"_\")[-1].rstrip(\"e.h5\")))[-1]\n",
    "            m = load_model(fpath, custom_objects={'mse': MeanSquaredError()})\n",
    "            return name, m.predict(X_cnn), fpath\n",
    "\n",
    "        if name == \"mlp\":\n",
    "            pattern = f\"{CLASS_BASE}/mlp_class/mlp_classifier_models/mlp_classifier_{solver}_{target}_*e.h5\"\n",
    "            files   = glob.glob(pattern)\n",
    "            if not files:\n",
    "                return name, None, None\n",
    "            fpath = sorted(files, key=lambda s: int(s.split(\"_\")[-1].rstrip(\"e.h5\")))[-1]\n",
    "            m = load_model(fpath, custom_objects={'mse': MeanSquaredError()})\n",
    "            return name, m.predict(X), fpath\n",
    "\n",
    "        if name == \"svm\":\n",
    "            p = f\"{CLASS_BASE}/svm_class/svm_classifier_models/svm_{solver}_{target}.joblib\"\n",
    "            if os.path.exists(p):\n",
    "                m = joblib.load(p); return name, m.predict_proba(X), p\n",
    "\n",
    "        if name == \"lr\":\n",
    "            p = f\"{CLASS_BASE}/lr_class/lr_classifier_models/lr_{solver}_{target}.joblib\"\n",
    "            if os.path.exists(p):\n",
    "                m = joblib.load(p); return name, m.predict_proba(X), p\n",
    "\n",
    "        if name == \"dt\":\n",
    "            p = f\"{CLASS_BASE}/dt_class/dt_classifier_models/dt_{solver}_{target}.joblib\"\n",
    "            if os.path.exists(p):\n",
    "                m = joblib.load(p); return name, m.predict_proba(X), p\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] loading {name}: {e}\")\n",
    "    return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae9517-6105-493c-a3ed-1368ad824870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_classifiers_for_solver(solver, train_file, test_file, val_file):\n",
    "    print(f\"\\n Solver: {solver} \")\n",
    "   \n",
    "    df_tr = pd.read_csv(train_file).dropna()\n",
    "    df_va = pd.read_csv(val_file).dropna()\n",
    "    df_te = pd.read_csv(test_file).dropna()\n",
    "\n",
    "   \n",
    "    bins_dir = os.path.join(BINS_BASE, f\"{solver}_bins\")\n",
    "    binf = glob.glob(os.path.join(bins_dir, \"*_bins.json\"))\n",
    "    assert len(binf)==1, \"Need one JSON in \"+bins_dir\n",
    "    bin_edges = json.load(open(binf[0]))\n",
    "\n",
    "    # scale features\n",
    "    feats = [\n",
    "      \"number_of_elements\",\"capacity\",\"max_weight\",\"min_weight\",\"mean_weight\",\n",
    "      \"median_weight\",\"std_weight\",\"weight_range\",\"max_profit\",\"min_profit\",\"mean_profit\",\n",
    "      \"median_profit\",\"std_profit\",\"profit_range\",\"renting_ratio\",\"mean_weight_profit_ratio\",\n",
    "      \"median_weight_profit_ratio\",\"capacity_mean_weight_ratio\",\"capacity_median_weight_ratio\",\n",
    "      \"capacity_std_weight_ratio\",\"std_weight_profit_ratio\",\"weight_profit_correlation\",\n",
    "      \"ram\",\"cpu_cores\"\n",
    "    ]\n",
    "    scaler = StandardScaler().fit(df_tr[feats])\n",
    "    X_va    = scaler.transform(df_va[feats])\n",
    "    X_te    = scaler.transform(df_te[feats])\n",
    "    X_va_cnn= X_va.reshape((-1,X_va.shape[1],1))\n",
    "    X_te_cnn= X_te.reshape((-1,X_te.shape[1],1))\n",
    "\n",
    "    records = []\n",
    "    for target in [\"solution_time\",\"optimality_gap\",\"peak_memory\"]:\n",
    "        # Recover true classes\n",
    "        edges = bin_edges[target]\n",
    "        def to_bins(arr,edges):\n",
    "            return np.clip(np.digitize(arr, edges[:-1], right=False)-1, 0, len(edges)-2)\n",
    "        y_va_raw = to_bins(df_va[target].values,edges)\n",
    "        y_te_raw = to_bins(df_te[target].values,edges)\n",
    "\n",
    "      \n",
    "        perf = {}\n",
    "        proba = {}\n",
    "        for name in [\"rf\",\"cb\",\"cnn\",\"mlp\",\"svm\",\"lr\",\"dt\"]:\n",
    "            nm, pr, path = load_classifier_proba(name, solver, target, X_va, X_va_cnn)\n",
    "            if pr is None: continue\n",
    "\n",
    "            y_va = np.clip(y_va_raw.copy(), 0, pr.shape[1] - 1)\n",
    "            y_te = np.clip(y_te_raw.copy(), 0, pr.shape[1] - 1)\n",
    "            ypred = pr.argmax(axis=1)\n",
    "            perf[nm] = f1_score(y_va, ypred, average=\"macro\", zero_division=0)\n",
    "            proba[nm] = pr\n",
    "            print(f\"  {nm:<3} val-F1 = {perf[nm]:.3f}\")\n",
    "\n",
    "        \n",
    "        if not perf:\n",
    "            print(f\"No classifiers for “{target}”, skip.\")\n",
    "            continue\n",
    "        # Rank by desc F1\n",
    "        ranked = sorted(perf, key=lambda m: perf[m], reverse=True)\n",
    " \n",
    "\n",
    "       \n",
    "        for K in K_LIST:\n",
    "            chosen = ranked[:K]\n",
    "\n",
    "           \n",
    "            all_probas = [\n",
    "                load_classifier_proba(m, solver, target, X_te, X_te_cnn)[1]\n",
    "                for m in chosen\n",
    "            ]\n",
    "            n_cls = max(pr.shape[1] for pr in all_probas)\n",
    "\n",
    "            padded = []\n",
    "            for pr in all_probas:\n",
    "                if pr.shape[1] < n_cls:\n",
    "                    pad_width = n_cls - pr.shape[1]\n",
    "                    pr = np.concatenate([pr, np.zeros((pr.shape[0], pad_width))], axis=1)\n",
    "                padded.append(pr)\n",
    "\n",
    "           \n",
    "            P = np.stack(padded, axis=0)      \n",
    "            P = P.mean(axis=0)                \n",
    "            y_pred = P.argmax(axis=1)\n",
    "\n",
    "            acc = accuracy_score(y_te, y_pred)\n",
    "            f1 = f1_score(y_te, y_pred, average=\"macro\", zero_division=0)\n",
    "            print(f\"Top-{K} ensemble test-F1 = {f1:.3f}\")\n",
    "\n",
    "            records.append({\n",
    "                \"solver\": solver,\n",
    "                \"target\": target,\n",
    "                \"Top_K\": K,\n",
    "                \"members\": \";\".join(chosen),\n",
    "                \"test_accuracy\": acc,\n",
    "                \"test_f1\": f1\n",
    "            })\n",
    "\n",
    "   \n",
    "    df_out = pd.DataFrame(records)\n",
    "    out_fp = os.path.join(CLASS_BASE, \"ensembles_fl\", f\"{solver}_class_ensembles.csv\")\n",
    "    os.makedirs(os.path.dirname(out_fp), exist_ok=True)\n",
    "    df_out.to_csv(out_fp, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f0cf1-8bf9-4f2b-bc04-87c7167a6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(base_folder):\n",
    "    for root, dirs, files in os.walk(base_folder):\n",
    "        for folder in dirs:\n",
    "            folder_path = os.path.join(root, folder)\n",
    "            csv_files = os.listdir(folder_path)\n",
    "\n",
    "            train_file = [f for f in csv_files if f.endswith(\"_train.csv\")]\n",
    "            test_file = [f for f in csv_files if f.endswith(\"_test.csv\")]\n",
    "            val_file = [f for f in csv_files if f.endswith(\"_val.csv\")]\n",
    "\n",
    "            if train_file and test_file and val_file:\n",
    "                train_fp = os.path.join(folder_path, train_file[0])\n",
    "                test_fp = os.path.join(folder_path, test_file[0])\n",
    "                val_fp = os.path.join(folder_path, val_file[0])\n",
    "\n",
    "                solver_name = folder  \n",
    "                ensemble_classifiers_for_solver(solver_name, train_fp, test_fp, val_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023f338-7f3c-4612-8246-e798e4d9a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_models(BASE_DPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af0a11-8b89-4528-845b-290d0a7e723f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
